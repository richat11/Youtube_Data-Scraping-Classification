{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_orignal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping NaN values\n",
    "df.dropna(subset = [\"title\",\"description\"], inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all the features separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_link = pd.DataFrame(columns = [\"link\"])        \n",
    "df_title = pd.DataFrame(columns = [\"title\"])        \n",
    "df_description = pd.DataFrame(columns = [\"description\"])        \n",
    "df_category = pd.DataFrame(columns = [\"category\"])        \n",
    "df_link['link'] = df['link'] \n",
    "df_title ['title']= df['title'] \n",
    "df_description['description'] = df['description'] \n",
    "df_category['category'] = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries for data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data and storing it into a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []        \n",
    "for i in range(0, df.shape[0]):         \n",
    "  review = re.sub('[^a-zA-Z]', ' ', df_title['title'][i])            \n",
    "  review = review.lower()            \n",
    "  review = review.split()            \n",
    "  ps = PorterStemmer()            \n",
    "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]            \n",
    "  review = ' '.join(review)            \n",
    "  corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = [] \n",
    "for i in range(0, df.shape[0]):            \n",
    "  review = re.sub('[^a-zA-Z]', ' ', df_description['description'][i])            \n",
    "  review = review.lower()            \n",
    "  review = review.split()            \n",
    "  ps = PorterStemmer()            \n",
    "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]            \n",
    "  review = ' '.join(review)            \n",
    "  corpus1.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing label encoding on the category feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "dfcategory = df_category.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataset after cleaning the data and label encoding the categories\n",
    "df_new = pd.concat([df_link, df_title, df_description, df_category], axis=1)##, join_axes = [df_link.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the bag of words model using countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "cv = CountVectorizer(max_features = 1500,ngram_range=(1,2)) \n",
    "X = cv.fit_transform(corpus, corpus1).toarray() \n",
    "y = df_new.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into the Training set and Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=1000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900990099009901"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Dance       1.00      1.00      1.00        21\n",
      "         Food       1.00      1.00      1.00        15\n",
      "      History       0.94      1.00      0.97        15\n",
      "Manufacturing       1.00      1.00      1.00        18\n",
      "      Science       1.00      0.92      0.96        13\n",
      "       Travel       1.00      1.00      1.00        19\n",
      "\n",
      "     accuracy                           0.99       101\n",
      "    macro avg       0.99      0.99      0.99       101\n",
      " weighted avg       0.99      0.99      0.99       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  0,  0,  0,  0,  0],\n",
       "       [ 0, 15,  0,  0,  0,  0],\n",
       "       [ 0,  0, 15,  0,  0,  0],\n",
       "       [ 0,  0,  0, 18,  0,  0],\n",
       "       [ 0,  0,  1,  0, 12,  0],\n",
       "       [ 0,  0,  0,  0,  0, 19]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier1 = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = classifier1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702970297029703"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  0,  0,  0,  0,  0],\n",
       "       [ 0, 15,  0,  0,  0,  0],\n",
       "       [ 1,  0, 14,  0,  0,  0],\n",
       "       [ 0,  1,  0, 17,  0,  0],\n",
       "       [ 1,  0,  0,  0, 12,  0],\n",
       "       [ 0,  0,  0,  0,  0, 19]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred1)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306930693069307"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  1,  0,  0,  0],\n",
       "       [ 0, 13,  0,  2,  0,  0],\n",
       "       [ 0,  0, 14,  1,  0,  0],\n",
       "       [ 0,  0,  1, 17,  0,  0],\n",
       "       [ 0,  0,  1,  0, 12,  0],\n",
       "       [ 0,  0,  0,  0,  1, 18]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm2 = confusion_matrix(y_test, y_pred2)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
